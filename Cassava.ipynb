{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import metrics\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-06T20:17:52.711394Z","iopub.execute_input":"2022-12-06T20:17:52.712037Z","iopub.status.idle":"2022-12-06T20:17:52.722270Z","shell.execute_reply.started":"2022-12-06T20:17:52.711996Z","shell.execute_reply":"2022-12-06T20:17:52.720266Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"!pip install --quiet efficientnet","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:34:06.687649Z","iopub.execute_input":"2022-12-06T19:34:06.688046Z","iopub.status.idle":"2022-12-06T19:34:15.513070Z","shell.execute_reply.started":"2022-12-06T19:34:06.688015Z","shell.execute_reply":"2022-12-06T19:34:15.511728Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import math, os, re, warnings, random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\n# from data_preparation import *\nfrom sklearn.utils import class_weight\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.activations import softmax\nfrom tensorflow.keras import optimizers, applications, Sequential, losses, metrics\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\nimport efficientnet.tfkeras as efn","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:34:15.515315Z","iopub.execute_input":"2022-12-06T19:34:15.515585Z","iopub.status.idle":"2022-12-06T19:34:23.231121Z","shell.execute_reply.started":"2022-12-06T19:34:15.515546Z","shell.execute_reply":"2022-12-06T19:34:23.230403Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"2022-12-06 19:34:17.385194: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-12-06 19:34:17.385343: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"}]},{"cell_type":"code","source":"def data_augment_v2(image,label):\n    p_cc=tf.random.uniform([],0,1.0,dtype=tf.float32)\n    p_h=tf.random.uniform([],0,1.0,dtype=tf.float32)\n    p_v=tf.random.uniform([],0,1.0,dtype=tf.float32)\n    \n    if p_cc>0.4:\n        image=tf.image.central_crop(image,0.75)\n    \n    if p_v>0.4:\n        image = tf.image.random_flip_up_down(image)\n    \n    if p_h>0.4:\n        image = tf.image.random_flip_left_right(image)\n    \n    \n    return image, label\n\ndef data_augment(image, label):\n    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    \n    # # Shear\n    # if p_shear > .2:\n    #     if p_shear > .6:\n    #         image = transform_shear(image, HEIGHT, shear=20.)\n    #     else:\n    #         image = transform_shear(image, HEIGHT, shear=-20.)\n            \n    # # Rotation\n    # if p_rotation > .2:\n    #     if p_rotation > .6:\n    #         image = transform_rotation(image, HEIGHT, rotation=45.)\n    #     else:\n    #         image = transform_rotation(image, HEIGHT, rotation=-45.)\n            \n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    \n    # if p_spatial > .75:\n    #     image = tf.image.transpose(image)\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) # rotate 270ยบ\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) # rotate 180ยบ\n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) # rotate 90ยบ\n        \n    # Pixel-level transforms\n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n        \n    # Crops\n    if p_crop > .7:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.6)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.8)\n    elif p_crop > .4:\n        crop_size = tf.random.uniform([], int(HEIGHT*.6), HEIGHT, dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n            \n    image = tf.image.resize(image, size=[HEIGHT, WIDTH])\n\n    return image, label\n\n\n\n# Datasets utility functions\ndef decode_image(image_data):\n    \"\"\"\n        1. Decode a JPEG-encoded image to a uint8 tensor.\n        2. Cast tensor to float and normalizes (range between 0 and 1).\n        3. Resize and reshape images to the expected size.\n    \"\"\"\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n                      \n    image = tf.image.resize(image, [HEIGHT, WIDTH])\n    image = tf.reshape(image, [HEIGHT, WIDTH, 3])\n    return image\n\ndef read_tfrecord(example, labeled=True):\n    \"\"\"\n        1. Parse data based on the 'TFREC_FORMAT' map.\n        2. Decode image.\n        3. If 'labeled' returns (image, label) if not (image, name).\n    \"\"\"\n    if labeled:\n        TFREC_FORMAT = {\n            'image': tf.io.FixedLenFeature([], tf.string), \n            'target': tf.io.FixedLenFeature([], tf.int64), \n        }\n    else:\n        TFREC_FORMAT = {\n            'image': tf.io.FixedLenFeature([], tf.string), \n            'image_name': tf.io.FixedLenFeature([], tf.string), \n        }\n    example = tf.io.parse_single_example(example, TFREC_FORMAT)\n    image = decode_image(example['image'])\n    if labeled:\n        label_or_name = tf.cast(example['target'], tf.int32)\n    else:\n        label_or_name =  example['image_name']\n    return image, label_or_name\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    \"\"\"\n        Create a Tensorflow dataset from TFRecords.\n    \"\"\"\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled), num_parallel_calls=AUTO)\n    return dataset\n\ndef get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False):\n    \"\"\"\n        Return a Tensorflow dataset ready for training or inference.\n    \"\"\"\n    dataset = load_dataset(FILENAMES, labeled=labeled, ordered=ordered)\n    if augment:\n        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    if repeated:\n        dataset = dataset.repeat()\n    if not ordered:\n        dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:34:23.232469Z","iopub.execute_input":"2022-12-06T19:34:23.232792Z","iopub.status.idle":"2022-12-06T19:34:23.254259Z","shell.execute_reply.started":"2022-12-06T19:34:23.232767Z","shell.execute_reply":"2022-12-06T19:34:23.253716Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 0\nseed_everything(seed)\nwarnings.filterwarnings('ignore')\n\n\n# TPU or GPU detection\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(f'Running on TPU {tpu.master()}')\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')\n\n\nBATCH_SIZE = 16 * REPLICAS\nLEARNING_RATE = 3e-5 * REPLICAS\n\nDEBUG=False\n\nif DEBUG:\n    EPOCHS = 1\n    N_FOLDS = 2\n    HEIGHT = 64\n    WIDTH = 64\nelse:\n    EPOCHS = 40\n    N_FOLDS = 5   \n    HEIGHT = 384\n    WIDTH = 384\n\n\n#For CPU Trial\n# HEIGHT = 128\n# WIDTH = 128\n\nCHANNELS = 3\nN_CLASSES = 5\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r'-([0-9]*)\\.').search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\n\ndatabase_base_path = '/kaggle/input/cassava-leaf-disease-classification/'\ntrain = pd.read_csv(f'{database_base_path}train.csv')\nprint(f'Train samples: {len(train)}')\n\nGCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification') \n\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train_tfrecords/*.tfrec') \n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n\nprint(f'GCS: train images: {NUM_TRAINING_IMAGES}')\ndisplay(train.head())\n\nCLASSES = ['Cassava Bacterial Blight', \n           'Cassava Brown Streak Disease', \n           'Cassava Green Mottle', \n           'Cassava Mosaic Disease', \n           'Healthy']\n\n\n# Model evaluation\ndef plot_metrics(history):\n    metric_list = [m for m in list(history.keys()) if m is not 'lr']\n    size = len(metric_list)//2\n    fig, axes = plt.subplots(size, 1, sharex='col', figsize=(20, size * 4))\n    if size > 1:\n        axes = axes.flatten()\n    else:\n        axes = [axes]\n    \n    for index in range(len(metric_list)//2):\n        metric_name = metric_list[index]\n        val_metric_name = metric_list[index+size]\n        axes[index].plot(history[metric_name], label='Train %s' % metric_name)\n        axes[index].plot(history[val_metric_name], label='Validation %s' % metric_name)\n        axes[index].legend(loc='best', fontsize=16)\n        axes[index].set_title(metric_name)\n        if 'loss' in metric_name:\n            axes[index].axvline(np.argmin(history[metric_name]), linestyle='dashed')\n            axes[index].axvline(np.argmin(history[val_metric_name]), linestyle='dashed', color='orange')\n        else:\n            axes[index].axvline(np.argmax(history[metric_name]), linestyle='dashed')\n            axes[index].axvline(np.argmax(history[val_metric_name]), linestyle='dashed', color='orange')\n\n    plt.xlabel('Epochs', fontsize=16)\n    sns.despine()\n    plt.show()\n    \ndef get_lr_callback():\n    lr_start   = 0.000001\n    lr_max     = 0.000005 * BATCH_SIZE\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max    \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n    return lr_callback\n\nweight_path_save = 'best_model.hdf5'\nlast_weight_path = 'last_model.hdf5'\n\ncheckpoint = ModelCheckpoint(weight_path_save, \n                             monitor= 'val_sparse_categorical_accuracy', \n                             verbose=1, \n                             save_best_only=True, \n                             mode= 'max', \n                             save_weights_only = False)\ncheckpoint_last = ModelCheckpoint(last_weight_path, \n                             monitor= 'val_sparse_categorical_accuracy', \n                             verbose=1, \n                             save_best_only=False, \n                             mode= 'max', \n                             save_weights_only = False)\n\n\nearly_stopping = EarlyStopping(monitor= 'val_sparse_categorical_accuracy', \n                      mode= 'max', \n                      min_delta=0.1,\n                      patience=5,\n                      restore_best_weights=True,\n                      verbose=1)\n\nLR_scheduler= get_lr_callback()\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=2, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.00001)\n\n# Loss Function\n# Bi Tempered Logistic Loss\n\ndef log_t(u, t):\n    epsilon = 1e-7\n    \"\"\"Compute log_t for `u`.\"\"\"\n    if t == 1.0:\n        return tf.math.log(u + epsilon)\n    else:\n        return (u**(1.0 - t) - 1.0) / (1.0 - t)\n\ndef exp_t(u, t):\n    \"\"\"Compute exp_t for `u`.\"\"\"\n    if t == 1.0:\n        return tf.math.exp(u)\n    else:\n        return tf.math.maximum(0.0, 1.0 + (1.0 - t) * u) ** (1.0 / (1.0 - t))\n\ndef bi_tempered_logistic_loss( y_true,y_pred, t1, label_smoothing=0.0):\n    \"\"\"Bi-Tempered Logistic Loss with custom gradient.\n    Args:\n    y_pred: A multi-dimensional probability tensor with last dimension `num_classes`.\n    y_true: A tensor with shape and dtype as y_pred.\n    t1: Temperature 1 (< 1.0 for boundedness).\n    label_smoothing: A float in [0, 1] for label smoothing.\n    Returns:\n    A loss tensor.\n    \"\"\"\n    y_pred = tf.cast(y_pred, tf.float32)\n    y_true = tf.cast(y_true, tf.float32)\n\n    if label_smoothing > 0.0:\n        num_classes = tf.cast(tf.shape(y_true)[-1], tf.float32)\n        y_true = (1 - num_classes /(num_classes - 1) * label_smoothing) * y_true + label_smoothing / (num_classes - 1)\n\n    temp1 = (log_t(y_true + 1e-7, t1) - log_t(y_pred, t1)) * y_true\n    temp2 = (1 / (2 - t1)) * (tf.math.pow(y_true, 2 - t1) - tf.math.pow(y_pred, 2 - t1))\n    loss_values = temp1 - temp2\n\n    return tf.math.reduce_sum(loss_values, -1)\n\nclass BiTemperedLogisticLoss(tf.keras.losses.Loss):\n    def __init__(self, t1=0.2, label_smoothing=0.1):\n        super(BiTemperedLogisticLoss, self).__init__()\n        self.t1 = t1\n        self.label_smoothing = label_smoothing\n\n    def call(self, y_true, y_pred):\n        return bi_tempered_logistic_loss(y_pred, y_true, self.t1, self.label_smoothing)\n    \nwith strategy.scope():\n    def model_fn_version_1(input_shape,N_CLASSES,base_model):\n        input_image = L.Input(shape=input_shape, name='input_image')\n        model = Sequential([\n                        base_model,\n                        L.Dropout(.25),\n                        L.Dense(32),\n                        L.Dense(N_CLASSES, activation='softmax', name='output')\n                    ])\n\n        optimizer = optimizers.SGD(lr=LEARNING_RATE)\n        metrics=['sparse_categorical_accuracy','accuracy']\n\n        label_smoothing = 0.1\n        t1=0.2\n        smoothed_btll=BiTemperedLogisticLoss(t1=t1, label_smoothing=label_smoothing)\n        \n        loss_function= smoothed_btll#tf.keras.losses.SparseCategoricalCrossentropy()\n\n        model.compile(optimizer=optimizer, \n                      loss=loss_function,\n                      metrics=metrics)\n\n\n        return model\n\n\n    def model_fn_version_2(input_shape,N_CLASSES,base_model):\n        input_image = L.Input(shape=input_shape, name='input_image')\n        model = Sequential([\n                        base_model,\n                        L.Dropout(.25),\n                        L.Dense(N_CLASSES, activation='softmax', name='output')\n                    ])\n\n        optimizer = optimizers.Adam(lr=LEARNING_RATE)\n        metrics=['sparse_categorical_accuracy','accuracy']\n\n        label_smoothing = 0.1\n        t1=0.2\n        smoothed_btll=BiTemperedLogisticLoss(t1=t1, label_smoothing=label_smoothing)\n        \n        loss_function= smoothed_btll#tf.keras.losses.SparseCategoricalCrossentropy()\n\n        model.compile(optimizer=optimizer, \n                      loss=loss_function,\n                      metrics=metrics)\n\n\n        return model","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:34:23.255904Z","iopub.execute_input":"2022-12-06T19:34:23.256093Z","iopub.status.idle":"2022-12-06T19:34:30.314623Z","shell.execute_reply.started":"2022-12-06T19:34:23.256070Z","shell.execute_reply":"2022-12-06T19:34:30.313957Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Running on TPU grpc://10.0.0.2:8470\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:34:23.290432: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-12-06 19:34:23.293527: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2022-12-06 19:34:23.293556: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2022-12-06 19:34:23.293578: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b4f9dd3f5968): /proc/driver/nvidia/version does not exist\n2022-12-06 19:34:23.296722: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-06 19:34:23.297935: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2022-12-06 19:34:23.334917: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2022-12-06 19:34:23.334977: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n2022-12-06 19:34:23.357381: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2022-12-06 19:34:23.357440: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n2022-12-06 19:34:23.359297: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30020\n","output_type":"stream"},{"name":"stdout","text":"REPLICAS: 8\nTrain samples: 21397\nGCS: train images: 21397\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:34:30.248793: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"         image_id  label\n0  1000015157.jpg      0\n1  1000201771.jpg      3\n2   100042118.jpg      1\n3  1000723321.jpg      1\n4  1000812911.jpg      3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000015157.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000201771.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100042118.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000723321.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000812911.jpg</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# EFFICIENT_NET_B0 TRAINING\n\nskf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\noof_pred = []; oof_labels = []; history_list = []\n\nfor fold,(idxT, idxV) in enumerate(skf.split(np.arange(16))):\n    if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    print(f'\\nFOLD: {fold+1}')\n    print(f'TRAIN: {idxT} VALID: {idxV}')\n\n    # Create train and validation sets\n#     FILENAMES= tf.io.gfile.glob(['/content/train_tfrecords/*.tfrec'])\n    FILENAMES= tf.io.gfile.glob([GCS_PATH + '/train_tfrecords/*.tfrec'])\n    TRAIN_FILENAMES = []\n    VALID_FILENAMES = []\n\n    for x in idxT:\n        TRAIN_FILENAMES.append(FILENAMES[x])\n\n    for x in idxV:\n        VALID_FILENAMES.append(FILENAMES[x])\n\n    ## MODEL\n    K.clear_session()\n\n    model_path=\"model_eff_b0_{}.h5\"\n\n    with strategy.scope():\n        base_model_efficient_net_b0=efn.EfficientNetB0(input_tensor=None,weights=None,include_top=False,pooling='avg')\n        # base_model_efficient_net_b0 = tf.keras.models.load_model('/content/model_eff_b0_4.h5')\n        model = model_fn_version_2((None, None, CHANNELS), N_CLASSES,base_model_efficient_net_b0)\n        # model.built = True\n        model.load_weights('../input/weightsb04/model_eff_b0_4.h5')\n\n    model_path = model_path.format(fold)     \n    train_data=get_dataset(TRAIN_FILENAMES, labeled=True, ordered=False, repeated=True, augment=True)\n    valid_data=get_dataset(VALID_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False)\n\n    callbacks_list= [checkpoint, checkpoint_last, early_stopping, LR_scheduler]\n    ct_train = count_data_items(TRAIN_FILENAMES)\n\n    ## TRAIN\n    history = model.fit(x=train_data, \n                        validation_data=valid_data, \n                        steps_per_epoch=(ct_train // BATCH_SIZE), \n                        callbacks=callbacks_list, #reduceLROnPlat, \n                        epochs=EPOCHS,  \n                        verbose=1).history\n\n    history_list.append(history)\n    # Save last model weights\n    model.save_weights(model_path)\n\n# OOF predictions\nds_valid = get_dataset(VALID_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False)\noof_labels.append([target.numpy() for img, target in iter(ds_valid.unbatch())])\nx_oof = ds_valid.map(lambda image, image_name: image)\noof_pred.append(np.argmax(model.predict(x_oof), axis=-1))\n\n## RESULTS\nprint(f\"#### FOLD {fold+1} OOF Accuracy = {np.max(history['val_sparse_categorical_accuracy']):.3f}\")\n\ny_true = np.concatenate(oof_labels)\ny_preds = np.concatenate(oof_pred)\n\nprint(classification_report(y_true, y_preds, target_names=CLASSES))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:34:30.315755Z","iopub.execute_input":"2022-12-06T19:34:30.315947Z","iopub.status.idle":"2022-12-06T20:01:23.217269Z","shell.execute_reply.started":"2022-12-06T19:34:30.315923Z","shell.execute_reply":"2022-12-06T20:01:23.216341Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\nFOLD: 1\nTRAIN: [ 0  2  3  4  5  7 10 11 12 13 14 15] VALID: [1 6 8 9]\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:34:40.266294: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 1e-06.\n125/125 [==============================] - 91s 347ms/step - loss: 15.6385 - sparse_categorical_accuracy: 0.8821 - accuracy: 0.8821 - val_loss: 15.3803 - val_sparse_categorical_accuracy: 0.9101 - val_accuracy: 0.9101\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:36:26.658782: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 28598, Output num: 0\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1670355386.655064833\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 28598, Output num: 0\",\"grpc_status\":3}\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 00001: val_sparse_categorical_accuracy improved from -inf to 0.91013, saving model to best_model.hdf5\n\nEpoch 00001: saving model to last_model.hdf5\nEpoch 2/40\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.00012880000000000001.\n125/125 [==============================] - 34s 271ms/step - loss: 15.4999 - sparse_categorical_accuracy: 0.4804 - accuracy: 0.4804 - val_loss: 15.0665 - val_sparse_categorical_accuracy: 0.3754 - val_accuracy: 0.3754\n\nEpoch 00002: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00002: saving model to last_model.hdf5\nEpoch 3/40\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.00025660000000000006.\n125/125 [==============================] - 35s 277ms/step - loss: 15.3043 - sparse_categorical_accuracy: 0.2529 - accuracy: 0.2529 - val_loss: 15.0651 - val_sparse_categorical_accuracy: 0.4572 - val_accuracy: 0.4572\n\nEpoch 00003: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00003: saving model to last_model.hdf5\nEpoch 4/40\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.0003844000000000001.\n125/125 [==============================] - 34s 272ms/step - loss: 15.3001 - sparse_categorical_accuracy: 0.2105 - accuracy: 0.2105 - val_loss: 15.0645 - val_sparse_categorical_accuracy: 0.2500 - val_accuracy: 0.2500\n\nEpoch 00004: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00004: saving model to last_model.hdf5\nEpoch 5/40\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.0005122000000000001.\n125/125 [==============================] - 34s 276ms/step - loss: 15.3172 - sparse_categorical_accuracy: 0.2145 - accuracy: 0.2145 - val_loss: 15.0644 - val_sparse_categorical_accuracy: 0.1491 - val_accuracy: 0.1491\n\nEpoch 00005: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00005: saving model to last_model.hdf5\nEpoch 6/40\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.00064.\n125/125 [==============================] - 35s 277ms/step - loss: 15.2637 - sparse_categorical_accuracy: 0.2140 - accuracy: 0.2140 - val_loss: 15.0647 - val_sparse_categorical_accuracy: 0.0888 - val_accuracy: 0.0888\n\nEpoch 00006: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00006: saving model to last_model.hdf5\nRestoring model weights from the end of the best epoch.\nEpoch 00006: early stopping\n\nFOLD: 2\nTRAIN: [ 0  1  3  5  6  7  8  9 10 11 12 14 15] VALID: [ 2  4 13]\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:39:46.289683: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 1e-06.\n135/135 [==============================] - 91s 325ms/step - loss: 15.6010 - sparse_categorical_accuracy: 0.8888 - accuracy: 0.8888 - val_loss: 15.7567 - val_sparse_categorical_accuracy: 0.9023 - val_accuracy: 0.9023\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:41:32.118204: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 111836, Output num: 1\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1670355692.117833821\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 111836, Output num: 1\",\"grpc_status\":3}\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 00001: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00001: saving model to last_model.hdf5\nEpoch 2/40\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.00012880000000000001.\n135/135 [==============================] - 37s 271ms/step - loss: 15.3251 - sparse_categorical_accuracy: 0.4591 - accuracy: 0.4591 - val_loss: 15.4476 - val_sparse_categorical_accuracy: 0.2459 - val_accuracy: 0.2459\n\nEpoch 00002: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00002: saving model to last_model.hdf5\nEpoch 3/40\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.00025660000000000006.\n135/135 [==============================] - 37s 273ms/step - loss: 15.1569 - sparse_categorical_accuracy: 0.2396 - accuracy: 0.2396 - val_loss: 15.4442 - val_sparse_categorical_accuracy: 0.3981 - val_accuracy: 0.3981\n\nEpoch 00003: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00003: saving model to last_model.hdf5\nEpoch 4/40\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.0003844000000000001.\n135/135 [==============================] - 37s 271ms/step - loss: 15.2712 - sparse_categorical_accuracy: 0.2205 - accuracy: 0.2205 - val_loss: 15.4428 - val_sparse_categorical_accuracy: 0.2576 - val_accuracy: 0.2576\n\nEpoch 00004: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00004: saving model to last_model.hdf5\nEpoch 5/40\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.0005122000000000001.\n135/135 [==============================] - 36s 270ms/step - loss: 15.2158 - sparse_categorical_accuracy: 0.2119 - accuracy: 0.2119 - val_loss: 15.4426 - val_sparse_categorical_accuracy: 0.1074 - val_accuracy: 0.1074\n\nEpoch 00005: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00005: saving model to last_model.hdf5\nEpoch 6/40\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.00064.\n135/135 [==============================] - 37s 274ms/step - loss: 15.2284 - sparse_categorical_accuracy: 0.2154 - accuracy: 0.2154 - val_loss: 15.4436 - val_sparse_categorical_accuracy: 0.0615 - val_accuracy: 0.0615\n\nEpoch 00006: val_sparse_categorical_accuracy did not improve from 0.91013\n\nEpoch 00006: saving model to last_model.hdf5\nRestoring model weights from the end of the best epoch.\nEpoch 00006: early stopping\n\nFOLD: 3\nTRAIN: [ 0  1  2  3  4  5  6  8  9 11 12 13 15] VALID: [ 7 10 14]\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:45:03.408741: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 1e-06.\n135/135 [==============================] - 91s 321ms/step - loss: 15.5551 - sparse_categorical_accuracy: 0.8861 - accuracy: 0.8861 - val_loss: 15.7335 - val_sparse_categorical_accuracy: 0.9163 - val_accuracy: 0.9163\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:46:49.831336: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 191472, Output num: 1\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1670356009.830788095\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 191472, Output num: 1\",\"grpc_status\":3}\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 00001: val_sparse_categorical_accuracy improved from 0.91013 to 0.91629, saving model to best_model.hdf5\n\nEpoch 00001: saving model to last_model.hdf5\nEpoch 2/40\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.00012880000000000001.\n135/135 [==============================] - 37s 271ms/step - loss: 15.3016 - sparse_categorical_accuracy: 0.4690 - accuracy: 0.4690 - val_loss: 15.4255 - val_sparse_categorical_accuracy: 0.2192 - val_accuracy: 0.2192\n\nEpoch 00002: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00002: saving model to last_model.hdf5\nEpoch 3/40\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.00025660000000000006.\n135/135 [==============================] - 37s 273ms/step - loss: 15.2303 - sparse_categorical_accuracy: 0.2249 - accuracy: 0.2249 - val_loss: 15.4211 - val_sparse_categorical_accuracy: 0.3560 - val_accuracy: 0.3560\n\nEpoch 00003: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00003: saving model to last_model.hdf5\nEpoch 4/40\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.0003844000000000001.\n135/135 [==============================] - 37s 274ms/step - loss: 15.2076 - sparse_categorical_accuracy: 0.2220 - accuracy: 0.2220 - val_loss: 15.4200 - val_sparse_categorical_accuracy: 0.2489 - val_accuracy: 0.2489\n\nEpoch 00004: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00004: saving model to last_model.hdf5\nEpoch 5/40\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.0005122000000000001.\n135/135 [==============================] - 37s 271ms/step - loss: 15.2456 - sparse_categorical_accuracy: 0.2169 - accuracy: 0.2169 - val_loss: 15.4199 - val_sparse_categorical_accuracy: 0.1495 - val_accuracy: 0.1495\n\nEpoch 00005: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00005: saving model to last_model.hdf5\nEpoch 6/40\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.00064.\n135/135 [==============================] - 37s 272ms/step - loss: 15.3285 - sparse_categorical_accuracy: 0.2139 - accuracy: 0.2139 - val_loss: 15.4198 - val_sparse_categorical_accuracy: 0.1121 - val_accuracy: 0.1121\n\nEpoch 00006: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00006: saving model to last_model.hdf5\nRestoring model weights from the end of the best epoch.\nEpoch 00006: early stopping\n\nFOLD: 4\nTRAIN: [ 0  1  2  4  5  6  7  8  9 10 12 13 14] VALID: [ 3 11 15]\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:50:22.806652: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 1e-06.\n135/135 [==============================] - 89s 323ms/step - loss: 15.5213 - sparse_categorical_accuracy: 0.8841 - accuracy: 0.8841 - val_loss: 15.6552 - val_sparse_categorical_accuracy: 0.8993 - val_accuracy: 0.8993\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:52:08.225370: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 274860, Output num: 1\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1670356328.224620919\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 274860, Output num: 1\",\"grpc_status\":3}\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 00001: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00001: saving model to last_model.hdf5\nEpoch 2/40\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.00012880000000000001.\n135/135 [==============================] - 37s 277ms/step - loss: 15.4666 - sparse_categorical_accuracy: 0.4665 - accuracy: 0.4665 - val_loss: 15.3441 - val_sparse_categorical_accuracy: 0.2383 - val_accuracy: 0.2383\n\nEpoch 00002: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00002: saving model to last_model.hdf5\nEpoch 3/40\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.00025660000000000006.\n135/135 [==============================] - 38s 279ms/step - loss: 15.3021 - sparse_categorical_accuracy: 0.2226 - accuracy: 0.2226 - val_loss: 15.3427 - val_sparse_categorical_accuracy: 0.4324 - val_accuracy: 0.4324\n\nEpoch 00003: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00003: saving model to last_model.hdf5\nEpoch 4/40\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.0003844000000000001.\n135/135 [==============================] - 37s 277ms/step - loss: 15.1466 - sparse_categorical_accuracy: 0.2099 - accuracy: 0.2099 - val_loss: 15.3421 - val_sparse_categorical_accuracy: 0.2411 - val_accuracy: 0.2411\n\nEpoch 00004: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00004: saving model to last_model.hdf5\nEpoch 5/40\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.0005122000000000001.\n135/135 [==============================] - 37s 277ms/step - loss: 15.1946 - sparse_categorical_accuracy: 0.2046 - accuracy: 0.2046 - val_loss: 15.3420 - val_sparse_categorical_accuracy: 0.1182 - val_accuracy: 0.1182\n\nEpoch 00005: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00005: saving model to last_model.hdf5\nEpoch 6/40\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.00064.\n135/135 [==============================] - 37s 278ms/step - loss: 15.2223 - sparse_categorical_accuracy: 0.2240 - accuracy: 0.2240 - val_loss: 15.3423 - val_sparse_categorical_accuracy: 0.1034 - val_accuracy: 0.1034\n\nEpoch 00006: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00006: saving model to last_model.hdf5\nRestoring model weights from the end of the best epoch.\nEpoch 00006: early stopping\n\nFOLD: 5\nTRAIN: [ 1  2  3  4  6  7  8  9 10 11 13 14 15] VALID: [ 0  5 12]\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:55:46.213549: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 1e-06.\n135/135 [==============================] - 91s 320ms/step - loss: 15.6595 - sparse_categorical_accuracy: 0.8946 - accuracy: 0.8946 - val_loss: 15.4901 - val_sparse_categorical_accuracy: 0.8642 - val_accuracy: 0.8642\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 19:57:32.415253: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 354496, Output num: 2\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1670356652.415003610\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 354496, Output num: 2\",\"grpc_status\":3}\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 00001: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00001: saving model to last_model.hdf5\nEpoch 2/40\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 0.00012880000000000001.\n135/135 [==============================] - 36s 270ms/step - loss: 15.4395 - sparse_categorical_accuracy: 0.4759 - accuracy: 0.4759 - val_loss: 15.1829 - val_sparse_categorical_accuracy: 0.1759 - val_accuracy: 0.1759\n\nEpoch 00002: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00002: saving model to last_model.hdf5\nEpoch 3/40\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.00025660000000000006.\n135/135 [==============================] - 37s 274ms/step - loss: 15.2644 - sparse_categorical_accuracy: 0.2375 - accuracy: 0.2375 - val_loss: 15.1801 - val_sparse_categorical_accuracy: 0.3426 - val_accuracy: 0.3426\n\nEpoch 00003: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00003: saving model to last_model.hdf5\nEpoch 4/40\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.0003844000000000001.\n135/135 [==============================] - 38s 280ms/step - loss: 15.2537 - sparse_categorical_accuracy: 0.2131 - accuracy: 0.2131 - val_loss: 15.1792 - val_sparse_categorical_accuracy: 0.2155 - val_accuracy: 0.2155\n\nEpoch 00004: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00004: saving model to last_model.hdf5\nEpoch 5/40\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.0005122000000000001.\n135/135 [==============================] - 37s 275ms/step - loss: 15.3396 - sparse_categorical_accuracy: 0.2129 - accuracy: 0.2129 - val_loss: 15.1792 - val_sparse_categorical_accuracy: 0.1574 - val_accuracy: 0.1574\n\nEpoch 00005: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00005: saving model to last_model.hdf5\nEpoch 6/40\n\nEpoch 00006: LearningRateScheduler reducing learning rate to 0.00064.\n135/135 [==============================] - 37s 274ms/step - loss: 15.3002 - sparse_categorical_accuracy: 0.2162 - accuracy: 0.2162 - val_loss: 15.1792 - val_sparse_categorical_accuracy: 0.1056 - val_accuracy: 0.1056\n\nEpoch 00006: val_sparse_categorical_accuracy did not improve from 0.91629\n\nEpoch 00006: saving model to last_model.hdf5\nRestoring model weights from the end of the best epoch.\nEpoch 00006: early stopping\n","output_type":"stream"},{"name":"stderr","text":"2022-12-06 20:01:09.782235: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 407513, Output num: 0\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\n:{\"created\":\"@1670356869.782106991\",\"description\":\"Error received from peer ipv4:10.0.0.2:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 407513, Output num: 0\",\"grpc_status\":3}\n","output_type":"stream"},{"name":"stdout","text":"#### FOLD 5 OOF Accuracy = 0.864\n                              precision    recall  f1-score   support\n\n    Cassava Bacterial Blight       0.59      0.63      0.61       192\nCassava Brown Streak Disease       0.83      0.78      0.81       434\n        Cassava Green Mottle       0.73      0.80      0.76       452\n      Cassava Mosaic Disease       0.97      0.93      0.95      2467\n                     Healthy       0.66      0.75      0.71       469\n\n                    accuracy                           0.86      4014\n                   macro avg       0.76      0.78      0.77      4014\n                weighted avg       0.87      0.86      0.87      4014\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\n# FileLink(r'last_model.hdf5')\nFileLink(r'best_model.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:35:58.913132Z","iopub.execute_input":"2022-12-06T20:35:58.913388Z","iopub.status.idle":"2022-12-06T20:35:58.919551Z","shell.execute_reply.started":"2022-12-06T20:35:58.913363Z","shell.execute_reply":"2022-12-06T20:35:58.918623Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/best_model.hdf5","text/html":"<a href='best_model.hdf5' target='_blank'>best_model.hdf5</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install mlxtend","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:13:08.387624Z","iopub.execute_input":"2022-12-06T20:13:08.387899Z","iopub.status.idle":"2022-12-06T20:13:14.912868Z","shell.execute_reply.started":"2022-12-06T20:13:08.387861Z","shell.execute_reply":"2022-12-06T20:13:14.912093Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Requirement already satisfied: mlxtend in /opt/conda/lib/python3.7/site-packages (0.19.0)\nRequirement already satisfied: scikit-learn>=0.20.3 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (0.23.2)\nRequirement already satisfied: pandas>=0.24.2 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (1.3.2)\nRequirement already satisfied: numpy>=1.16.2 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (1.19.5)\nRequirement already satisfied: joblib>=0.13.2 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (1.0.1)\nRequirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (3.4.3)\nRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (1.7.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from mlxtend) (57.4.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (8.2.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.15.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.2->mlxtend) (2021.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.20.3->mlxtend) (2.2.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_true, y_preds, target_names=CLASSES))","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:07:22.270689Z","iopub.execute_input":"2022-12-06T20:07:22.270972Z","iopub.status.idle":"2022-12-06T20:07:22.283920Z","shell.execute_reply.started":"2022-12-06T20:07:22.270943Z","shell.execute_reply":"2022-12-06T20:07:22.283318Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"                              precision    recall  f1-score   support\n\n    Cassava Bacterial Blight       0.59      0.63      0.61       192\nCassava Brown Streak Disease       0.83      0.78      0.81       434\n        Cassava Green Mottle       0.73      0.80      0.76       452\n      Cassava Mosaic Disease       0.97      0.93      0.95      2467\n                     Healthy       0.66      0.75      0.71       469\n\n                    accuracy                           0.86      4014\n                   macro avg       0.76      0.78      0.77      4014\n                weighted avg       0.87      0.86      0.87      4014\n\n","output_type":"stream"}]},{"cell_type":"code","source":"conf_mat=metrics.confusion_matrix(y_true, y_preds)\nconf_matl","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:39:32.648534Z","iopub.execute_input":"2022-12-06T20:39:32.648770Z","iopub.status.idle":"2022-12-06T20:39:32.666544Z","shell.execute_reply.started":"2022-12-06T20:39:32.648746Z","shell.execute_reply":"2022-12-06T20:39:32.665197Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"array([[ 121,   14,    5,    8,   44],\n       [  25,  338,   11,   13,   47],\n       [   8,   13,  361,   31,   39],\n       [  10,   15,   96, 2297,   49],\n       [  42,   25,   24,   24,  354]])"},"metadata":{}}]},{"cell_type":"code","source":"from mlxtend.plotting import plot_confusion_matrix\nplt.figure(figsize=(14,5))\nplot_confusion_matrix(conf_mat,class_names=CLASSES)\nplt.xticks(rotation = 90)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:27:18.379030Z","iopub.execute_input":"2022-12-06T20:27:18.379330Z","iopub.status.idle":"2022-12-06T20:27:18.568579Z","shell.execute_reply.started":"2022-12-06T20:27:18.379300Z","shell.execute_reply":"2022-12-06T20:27:18.567810Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(array([0, 1, 2, 3, 4]),\n [Text(0, 0, 'Cassava Bacterial Blight'),\n  Text(1, 0, 'Cassava Brown Streak Disease'),\n  Text(2, 0, 'Cassava Green Mottle'),\n  Text(3, 0, 'Cassava Mosaic Disease'),\n  Text(4, 0, 'Healthy')])"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x360 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}